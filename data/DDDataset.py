import os
import numpy as np
import scipy.sparse as sp
from sklearn.model_selection import train_test_split

class DDDataset(object):
    def __init__(self, random_state=1, data_root="data", train_size=0.8, valid_size=0.1, test_size=0.1):
        self.data_root = data_root
        sparse_adjacency, node_features, graph_indicator, graph_labels, atten_score = self.read_data()
        # converting coo format to csr for sparse matrix operation
        self.sparse_adjacency = sparse_adjacency.tocsr()
        self.node_features = node_features
        self.graph_indicator = graph_indicator
        self.graph_labels = graph_labels
        self.atten_score = atten_score
        self.random_state = random_state
        self.train_index,self.valid_index, self.test_index = self.split_data(train_size,valid_size, test_size)
        self.train_label = graph_labels[self.train_index]  # labels of all graphs in the training set
        self.valid_label = graph_labels[self.valid_index]  # labels of all graphs in the valid set
        self.test_label = graph_labels[self.test_index]  # labels of all graphs in the test set

    def split_data(self, train_size, valid_size, test_size):
        unique_indicator = np.asarray(list(set(self.graph_indicator)))
        # the training set and test set are randomly divided, and get their corresponding graph indexes
        train_index, test_index = train_test_split(unique_indicator, train_size=1 - test_size, random_state=self.random_state)
        train_index, valid_index = train_test_split(np.asarray(train_index), train_size=train_size / (1 - test_size),random_state=self.random_state)
        return train_index, valid_index, test_index
    def __getitem__(self, index):
        # get all nodes corresponding to the graph whose index is index
        mask = self.graph_indicator == index
        graph_indicator = self.graph_indicator[mask]
        # feature label corresponding to each node
        node_features = self.node_features[mask]
        # label corresponding to the figure
        graph_labels = self.graph_labels[index]
        # adjacency matrix corresponding to the graph
        adjacency = self.sparse_adjacency[mask, :][:, mask]
        return adjacency, node_features, graph_indicator, graph_labels
    def __len__(self):
        return len(self.graph_labels)

    def read_data(self):
        # unzipped path
        data_dir = os.path.join(self.data_root, "DAC")
        print("Loading DD_A.txt")
        adjacency_list = np.genfromtxt('data/DD/DD_A.txt',
                                       dtype=np.int64, delimiter=',')
        print("Loading DAC_node_labels.txt")
        node_labels = np.genfromtxt('data/DD/DD_node_labels.txt',
                                    dtype=np.float32)

        print("Loading DAC_graph_indicator.txt")
        # which graph does each node belong to
        graph_indicator = np.genfromtxt(
            'data/DD/DD_graph_indicator.txt',
            dtype=np.int64)
        print("Loading DAC_graph_labels.txt")

        graph_labels = np.genfromtxt('data/DD/DD_graph_labels.txt',
                                     dtype=np.float32)
        num_nodes = len(node_labels)  # 节点数 （包含所有图的节点）
        # The adjacency matrix is generated by adjacency table, and the sparse storage in coo format is used to save memory
        sparse_adjacency = sp.coo_matrix((np.ones(len(adjacency_list)),
                                          (adjacency_list[:, 0], adjacency_list[:, 1])),
                                         shape=(num_nodes, num_nodes), dtype=np.float32)
        print("Number of nodes: ", num_nodes)

        print("Loading DAC_atten_scores.txt")
        # nodes of focused attention
        atten_score = np.genfromtxt('data/DD/DD_atten_scores.txt', dtype=np.bool)
        return sparse_adjacency, node_labels, graph_indicator, graph_labels,atten_score
